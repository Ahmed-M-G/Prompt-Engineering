{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jOE0yGqJ6Yk9",
        "qUvWnhZX7Upe",
        "1hzORblI-Icl",
        "dal9m0jz-mDn",
        "_HWuN3Mf_Cps",
        "F2rsvfcL_xpZ",
        "-oewbY_QAPlE",
        "gv11PpWyAr9Y",
        "Pkc_Km6jCe-l"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Work Environment"
      ],
      "metadata": {
        "id": "jOE0yGqJ6Yk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AafKYYd-wuUM",
        "outputId": "35c8080e-7c26-4a21-b790-662c6e16874c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.171.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-genai"
      ],
      "metadata": {
        "id": "kvESO7_a1x1d",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76bcb1c9-6a1b-41ab-937e-e50775f5bc9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/203.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m194.6/203.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install redlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHK9dlauDLLY",
        "outputId": "f7a00bea-2e69-427c-a2d4-f503147d07a1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting redlines\n",
            "  Downloading redlines-0.5.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from redlines) (8.2.1)\n",
            "Collecting rich-click>=1.6.1 (from redlines)\n",
            "  Downloading rich_click-1.8.9-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: rich>=13.3.5 in /usr/local/lib/python3.11/dist-packages (from redlines) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.5->redlines) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.5->redlines) (2.19.1)\n",
            "Requirement already satisfied: typing_extensions>=4 in /usr/local/lib/python3.11/dist-packages (from rich-click>=1.6.1->redlines) (4.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.5->redlines) (0.1.2)\n",
            "Downloading redlines-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading rich_click-1.8.9-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: rich-click, redlines\n",
            "Successfully installed redlines-0.5.2 rich-click-1.8.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "import google.generativeai as ggenai\n",
        "from google.colab import userdata\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "from PIL import Image\n",
        "from google.genai import types\n",
        "\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "qdoxw_y2v5UH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the API key (Replace 'YOUR_API_KEY' with your actual Gemini API key)\n",
        "key = userdata.get('genai_api')\n",
        "client = genai.Client(api_key=key)"
      ],
      "metadata": {
        "id": "dK9gy8xMvlOV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "List the set of available models"
      ],
      "metadata": {
        "id": "wR9WQ3B76c3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggenai.configure(api_key=key)\n",
        "\n",
        "models = ggenai.list_models()\n",
        "for model in models:\n",
        "    print(model.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "DKPmEKApyY0Q",
        "outputId": "4932fbc0-875f-4681-e929-9271cd7e93d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/aqa\n",
            "models/imagen-3.0-generate-002\n",
            "models/veo-2.0-generate-001\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3\n",
            "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a helper function to make it easier to use prompts and look at generated outputs."
      ],
      "metadata": {
        "id": "P1R9gVXz6e62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gemini-1.5-flash\"):\n",
        "  response = client.models.generate_content(\n",
        "      model=model,\n",
        "      contents=prompt,\n",
        "      config=types.GenerateContentConfig(max_output_tokens=100, temperature=0.1)\n",
        "      )\n",
        "  return response.text  # Extract the generated text"
      ],
      "metadata": {
        "id": "Nho4Ne_Yv_AW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Translation\n",
        "\n",
        "Large language models are trained on vast amounts of text from diverse sources, including content in many different languages. As a result, they can perform translation tasks across a wide range of languages with varying levels of proficiency.\n",
        "\n",
        "In the following example, we’ll demonstrate this capability by translating a sentence from English to Arabic. The prompt is:\n",
        "\n",
        "\"Translate the following English text into Arabic: 'Hi, I would like to order a new book.'\"\n",
        "\n",
        "Here is the model’s response:"
      ],
      "metadata": {
        "id": "qUvWnhZX7Upe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Arabic: \\\n",
        "```Hi, I would like to order a new book```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbibzt8L9p5T",
        "outputId": "83d1a055-d1bd-46f5-da07-f76d74a60ed0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are several ways to translate \"Hi, I would like to order a new book\" to Arabic, depending on the level of formality. Here are a few options:\n",
            "\n",
            "**Informal:**\n",
            "\n",
            "* **مرحباً، أريد أن أطلب كتابًا جديدًا.** (Marhaban, ureedu an atulib kitabān jadeedan.)  This is a straightforward and common translation.\n",
            "\n",
            "**Slightly more formal:**\n",
            "\n",
            "* **أهلًا، أودّ طلب كتاب جديد.** (A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Arabic in a formal way: \\\n",
        "```Hi, I would like to order a new book```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc0m4ZRT95_9",
        "outputId": "44e08c08-01ec-423e-89d9-2e01a229cc26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Several formal translations are possible, depending on the nuance you want to convey. Here are a few options:\n",
            "\n",
            "* **السلام عليكم، أودّ طلب كتاب جديد.** (As-salāmu `alaykum, `Uddu tilab kitāb jadīd.)  This is a very polite option, starting with the traditional Arabic greeting \"Peace be upon you.\"\n",
            "\n",
            "* **أودّ طلب كتاب جديد.** (`Uddu tilab kitāb jadīd.) This is a more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Detection"
      ],
      "metadata": {
        "id": "1hzORblI-Icl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaTIsxRE-IFI",
        "outputId": "da47c820-7d63-4734-cb51-88db92035718"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's French.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```كيف حالك```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ_O_Rpr-CQ3",
        "outputId": "f4efcfc6-c94c-4d31-b1bb-6a9a47a32628"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's Arabic.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# multiple Translations\n",
        "\n",
        "Large language models can also handle multiple translations in a single prompt. In this example, we’ll ask the model to translate a sentence into French, Spanish, and Arabic.\n",
        "\n",
        "The text to be translated is:\n",
        "\"I want to order a book and get it delivered to my home and make sure that the book is packaged in a good way so it will arrive in a good form.\"\n",
        "\n",
        "Let’s run the prompt and see how the model performs across all three languages."
      ],
      "metadata": {
        "id": "dal9m0jz-mDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and Arabic: \\\n",
        "```I want to order a football```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGrYK4s9-Z1X",
        "outputId": "633d8709-9d4f-40bc-b45e-d5f83874cadd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the translations:\n",
            "\n",
            "* **French:** Je veux commander un ballon de football.  (More natural: Je voudrais commander un ballon de foot.)\n",
            "\n",
            "* **Spanish:** Quiero pedir un balón de fútbol. (More natural: Quiero encargar un balón de fútbol. or  Quiero un balón de fútbol, por favor.)\n",
            "\n",
            "* **Arabic:** أريد أن أطلب كرة قدم. (ʾurīdu an ʾaṭlub kurat qadam)\n",
            "\n",
            "\n",
            "The more natural translations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Way of Translation\n",
        "\n",
        "In some languages, translation can vary based on the relationship between the speaker and the listener, such as using formal or informal language. You can guide a large language model to take this context into account by including it in the prompt.\n",
        "\n",
        "This allows the model to provide translations that are appropriate for different social contexts."
      ],
      "metadata": {
        "id": "_HWuN3Mf_Cps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to French in both the \\\n",
        "formal and informal forms:\n",
        "'Would you like to order a pillow?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_RWKYvM-14X",
        "outputId": "9b69451f-3a32-4430-ec06-12aa57907219"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Formal:**\n",
            "\n",
            "* \"Souhaiteriez-vous commander un oreiller ?\"\n",
            "\n",
            "**Informal:**\n",
            "\n",
            "* \"Tu veux commander un oreiller ?\"\n",
            "\n",
            "\n",
            "The formal version uses \"Souhaiteriez-vous\" (Would you like to?), a more polite and respectful phrasing. The informal version uses \"Tu veux\" (Do you want to?), which is suitable for friends or family.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Universal Translator Use Case\n",
        "\n",
        "Imagine you're the head of IT at a large multinational e-commerce company. Employees from around the world are reaching out with technical issues each in their native language. Meanwhile, your IT support staff also speaks a variety of different languages, often limited to their own.\n",
        "\n",
        "To bridge this communication gap, you need a universal translator—a solution that can automatically detect and translate messages between languages, enabling seamless communication across your global team."
      ],
      "metadata": {
        "id": "F2rsvfcL_xpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal\n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
        "]"
      ],
      "metadata": {
        "id": "SHDV0oto_cFU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Arabic: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8SJ1XQx_8OX",
        "outputId": "2fb6a33d-0526-4281-c563-3f052ea25ea4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original message (That's French.\n",
            "): La performance du système est plus lente que d'habitude.\n",
            "**English Translation:**\n",
            "\n",
            "The system performance is slower than usual.\n",
            "\n",
            "\n",
            "**Arabic Translation:**\n",
            "\n",
            "أداء النظام أبطأ من المعتاد.  (ʾAdāʾ al-niẓām ʾabṭaʾ min al-muʿtād.)\n",
            "\n",
            "\n",
            "The Arabic translation uses the following:\n",
            "\n",
            "* **أداء (ʾAdāʾ):** Performance\n",
            "* **النظام (al-niẓām):** The system\n",
            "* **أبطأ (ʾabṭ \n",
            "\n",
            "Original message (That's Spanish.\n",
            "): Mi monitor tiene píxeles que no se iluminan.\n",
            "**English:** My monitor has pixels that are not lighting up.  (Or: My monitor has dead pixels.)\n",
            "\n",
            "\n",
            "**Arabic:**  شاشتي بها بكسلات لا تضيء. (Shāshitī bihā biksilāt lā tuḍī'.)\n",
            " \n",
            "\n",
            "Original message (That's Italian.  The sentence translates to \"My mouse isn't working.\"\n",
            "): Il mio mouse non funziona\n",
            "The Italian phrase \"Il mio mouse non funziona\" translates to:\n",
            "\n",
            "* **English:** My mouse isn't working.  (or My mouse is not working.)\n",
            "\n",
            "* **Arabic:**  ماوسي لا يعمل (Mawsī lā ya'mal)\n",
            "\n",
            "\n",
            "The Arabic translation is a fairly direct equivalent.  There might be slight variations depending on the dialect, but this is a widely understood form.\n",
            " \n",
            "\n",
            "Original message (That's Polish.  The sentence translates to \"My Ctrl key is broken\".\n",
            "): Mój klawisz Ctrl jest zepsuty\n",
            "**English:** My Ctrl key is broken.\n",
            "\n",
            "\n",
            "**Arabic:** مفتاحي Ctrl معطل.  (Miftāḥī Ctrl muʿaṭṭal.)\n",
            " \n",
            "\n",
            "Original message (That's **Chinese (simplified characters)**.\n",
            "): 我的屏幕在闪烁\n",
            "The English translation of \"我的屏幕在闪烁\" (wǒ de píngmù zài shǎnshuò) is:\n",
            "\n",
            "**My screen is flickering.**\n",
            "\n",
            "\n",
            "The Arabic translation depends slightly on context (is it a computer screen, a phone screen, a TV screen etc.), but a good general translation would be:\n",
            "\n",
            "**شاشتي تومض (shāshitī tūmiḍ)**\n",
            "\n",
            "This translates literally to \"My screen is blinking/flashing\".  You could \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tone & Text Transformation\n",
        "\n",
        "Writing can vary based on the intended audience. LLMs can produce different tones"
      ],
      "metadata": {
        "id": "-oewbY_QAPlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Transform the following from slang to a business letter:\n",
        "'Dude, This is Ahmed Gaber, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy59F9UY_9g8",
        "outputId": "f517b8ae-f077-4e31-cb3f-89755bf5ef42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: Product Specification: Standing Lamp\n",
            "\n",
            "Dear [Recipient Name],\n",
            "\n",
            "My name is Ahmed Gaber.  Attached please find the product specification for the standing lamp.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "Ahmed Gaber\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting Between Text Formats\n",
        "\n",
        "Large language models are highly effective at translating between different text formats, such as converting JSON to HTML, XML, or Markdown. To perform this type of conversion, you simply need to clearly describe both the input format and the desired output format in your prompt."
      ],
      "metadata": {
        "id": "gv11PpWyAr9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIFAXvtTAd_8",
        "outputId": "e10be0fb-af60-497e-992b-70ecc171d2d9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```html\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "<title>Restaurant Employees</title>\n",
            "<style>\n",
            "table {\n",
            "  width: 50%;\n",
            "  border-collapse: collapse;\n",
            "}\n",
            "\n",
            "th, td {\n",
            "  border: 1px solid black;\n",
            "  padding: 8px;\n",
            "  text-align: left;\n",
            "}\n",
            "\n",
            "th {\n",
            "  background-color: #f2f2f2;\n",
            "}\n",
            "</style>\n",
            "</head>\n",
            "<body>\n",
            "\n",
            "<h1>Restaurant Employees</h1>\n",
            "\n",
            "<table>\n",
            "  <tr>\n",
            "    <th>Name</th>\n",
            "    <th>Email</th>\n",
            "  </tr>\n",
            "  <tr>\n",
            "    <td>Shyam</td>\n",
            "    <td>shyamjaiswal@gmail.com</td>\n",
            "  </tr>\n",
            "  <tr>\n",
            "    <td>Bob</td>\n",
            "    <td>bob32@gmail.com</td>\n",
            "  </tr>\n",
            "  <tr>\n",
            "    <td>Jai</td>\n",
            "    <td>jai87@gmail.com</td>\n",
            "  </tr>\n",
            "</table>\n",
            "\n",
            "</body>\n",
            "</html>\n",
            "```\n",
            "\n",
            "This HTML code directly creates the table.  To generate this from the JSON dynamically using Python, you would use a library like `json` to parse the JSON and then generate the HTML string. Here's how you could do that:\n",
            "\n",
            "\n",
            "```python\n",
            "import json\n",
            "\n",
            "json_data = \"\"\"\n",
            "{'resturant employees': [{'name': 'Shyam', 'email': 'shyamjaiswal@gmail.com'}, {'name': 'Bob', 'email': 'bob32@gmail.com'}, {'name': 'Jai', 'email': 'jai87@gmail.com'}]}\n",
            "\"\"\"\n",
            "\n",
            "data = json.loads(json_data)\n",
            "employees = data['resturant employees']\n",
            "\n",
            "html_string = \"\"\"<!DOCTYPE html>\n",
            "<html>\n",
            "<head>\n",
            "<title>Restaurant Employees</title>\n",
            "<style>\n",
            "table {\n",
            "  width: 50%;\n",
            "  border-collapse: collapse;\n",
            "}\n",
            "\n",
            "th, td {\n",
            "  border: 1px solid black;\n",
            "  padding: 8px;\n",
            "  text-align: left;\n",
            "}\n",
            "\n",
            "th {\n",
            "  background-color: #f2f2f2;\n",
            "}\n",
            "</style>\n",
            "</head>\n",
            "<body>\n",
            "\n",
            "<h1>Restaurant Employees</h1>\n",
            "\n",
            "<table>\n",
            "  <tr>\n",
            "    <th>Name</th>\n",
            "    <th>Email</th>\n",
            "  </tr>\"\"\"\n",
            "\n",
            "for employee in employees:\n",
            "    html_string += f\"\"\"\n",
            "  <tr>\n",
            "    <td>{employee['name']}</td>\n",
            "    <td>{employee['email']}</td>\n",
            "  </tr>\"\"\"\n",
            "\n",
            "html_string += \"\"\"\n",
            "</table>\n",
            "\n",
            "</body>\n",
            "</html>\"\"\"\n",
            "\n",
            "print(html_string)\n",
            "\n",
            "#To save to a file:\n",
            "with open(\"employees.html\", \"w\") as f:\n",
            "    f.write(html_string)\n",
            "```\n",
            "\n",
            "This Python script parses the JSON, iterates through the employee data, and constructs the HTML table dynamically.  The resulting HTML is then printed to the console or saved to a file named `employees.html`.  Remember to have the `json` library installed (it's usually included with Python).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_response = response.strip().removeprefix(\"```html\").removesuffix(\"```\").strip()"
      ],
      "metadata": {
        "id": "Rbmi7ejVBkpX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
        "display(HTML(cleaned_response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "lhbisPbHBAFF",
        "outputId": "ee633252-934d-447a-e7f5-3f25d8a52233"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<title>Restaurant Employees</title>\n",
              "<style>\n",
              "table {\n",
              "  width: 50%;\n",
              "  border-collapse: collapse;\n",
              "}\n",
              "\n",
              "th, td {\n",
              "  border: 1px solid black;\n",
              "  padding: 8px;\n",
              "  text-align: left;\n",
              "}\n",
              "\n",
              "th {\n",
              "  background-color: #f2f2f2;\n",
              "}\n",
              "</style>\n",
              "</head>\n",
              "<body>\n",
              "\n",
              "<h1>Restaurant Employees</h1>\n",
              "\n",
              "<table>\n",
              "  <tr>\n",
              "    <th>Name</th>\n",
              "    <th>Email</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td>Shyam</td>\n",
              "    <td>shyamjaiswal@gmail.com</td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td>Bob</td>\n",
              "    <td>bob32@gmail.com</td>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td>Jai</td>\n",
              "    <td>jai87@gmail.com</td>\n",
              "  </tr>\n",
              "</table>\n",
              "\n",
              "</body>\n",
              "</html>\n",
              "```\n",
              "\n",
              "This HTML code directly creates the table.  To generate this from the JSON dynamically using Python, you would use a library like `json` to parse the JSON and then generate the HTML string. Here's how you could do that:\n",
              "\n",
              "\n",
              "```python\n",
              "import json\n",
              "\n",
              "json_data = \"\"\"\n",
              "{'resturant employees': [{'name': 'Shyam', 'email': 'shyamjaiswal@gmail.com'}, {'name': 'Bob', 'email': 'bob32@gmail.com'}, {'name': 'Jai', 'email': 'jai87@gmail.com'}]}\n",
              "\"\"\"\n",
              "\n",
              "data = json.loads(json_data)\n",
              "employees = data['resturant employees']\n",
              "\n",
              "html_string = \"\"\"<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "<title>Restaurant Employees</title>\n",
              "<style>\n",
              "table {\n",
              "  width: 50%;\n",
              "  border-collapse: collapse;\n",
              "}\n",
              "\n",
              "th, td {\n",
              "  border: 1px solid black;\n",
              "  padding: 8px;\n",
              "  text-align: left;\n",
              "}\n",
              "\n",
              "th {\n",
              "  background-color: #f2f2f2;\n",
              "}\n",
              "</style>\n",
              "</head>\n",
              "<body>\n",
              "\n",
              "<h1>Restaurant Employees</h1>\n",
              "\n",
              "<table>\n",
              "  <tr>\n",
              "    <th>Name</th>\n",
              "    <th>Email</th>\n",
              "  </tr>\"\"\"\n",
              "\n",
              "for employee in employees:\n",
              "    html_string += f\"\"\"\n",
              "  <tr>\n",
              "    <td>{employee['name']}</td>\n",
              "    <td>{employee['email']}</td>\n",
              "  </tr>\"\"\"\n",
              "\n",
              "html_string += \"\"\"\n",
              "</table>\n",
              "\n",
              "</body>\n",
              "</html>\"\"\"\n",
              "\n",
              "print(html_string)\n",
              "\n",
              "#To save to a file:\n",
              "with open(\"employees.html\", \"w\") as f:\n",
              "    f.write(html_string)\n",
              "```\n",
              "\n",
              "This Python script parses the JSON, iterates through the employee data, and constructs the HTML table dynamically.  The resulting HTML is then printed to the console or saved to a file named `employees.html`.  Remember to have the `json` library installed (it's usually included with Python)."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proofreading with Language Models\n",
        "\n",
        "You can use a large language model to help identify and correct common grammar and spelling mistakes. To signal that your goal is proofreading, simply include instructions like \"proofread\" or \"proofread and correct\" in your prompt.\n",
        "\n",
        "Below are some examples of typical grammar and spelling issues, along with how the model responds to correct them."
      ],
      "metadata": {
        "id": "Pkc_Km6jCe-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\n",
        "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
        "  \"Yolanda has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
        "]"
      ],
      "metadata": {
        "id": "Kz_rALndB_TM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in text:\n",
        "    prompt = f\"\"\"Proofread and correct the following text\n",
        "    and rewrite the corrected version. If you don't find\n",
        "    and errors, just say \"No errors found\". Don't use\n",
        "    any punctuation around the text:\n",
        "    ```{t}```\"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRE3fwGTCw4g",
        "outputId": "9e8238ce-c5c8-423a-b8fe-290fb6293b9c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The girl with the black and white puppies has a ball\n",
            "\n",
            "No errors found\n",
            "\n",
            "It's going to be a long day Does the car need its oil changed\n",
            "\n",
            "There goes my freedom There are going to bring their suitcases\n",
            "\n",
            "You're going to need your notebook\n",
            "\n",
            "That medicine affects my ability to sleep Have you heard of the butterfly effect\n",
            "\n",
            "This phrase is to check ChatGPT's spelling ability\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YvL2iV3yCxJY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSz5B2kpDAkD",
        "outputId": "c9755ed5-89c2-46e0-8574-9abe18af39a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I bought this panda for my daughter's birthday because she keeps taking mine from my room.  Yes, adults like pandas too! She takes it everywhere, and it's super soft and cute. However, one ear is slightly lower than the other; I don't think this was intentional.  It's also a bit smaller than I expected for the price.  There may be larger options available for the same cost.  It arrived a day early, which allowed me to enjoy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from redlines import Redlines\n",
        "\n",
        "diff = Redlines(text,response)\n",
        "display(Markdown(diff.output_markdown))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "rlJwJvpODDAm",
        "outputId": "8d211522-64a9-4fd9-c5f4-b79395541f48"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<span style='color:red;font-weight:700;text-decoration:line-through;'>Got </span><span style='color:green;font-weight:700;'>I bought </span>this <span style='color:green;font-weight:700;'>panda </span>for my <span style='color:red;font-weight:700;text-decoration:line-through;'>daughter for her </span><span style='color:green;font-weight:700;'>daughter's </span>birthday <span style='color:red;font-weight:700;text-decoration:line-through;'>cuz </span><span style='color:green;font-weight:700;'>because </span>she keeps taking mine from my room.  Yes, adults <span style='color:red;font-weight:700;text-decoration:line-through;'>also </span>like pandas <span style='color:red;font-weight:700;text-decoration:line-through;'>too.  </span><span style='color:green;font-weight:700;'>too! </span>She takes it <span style='color:red;font-weight:700;text-decoration:line-through;'>everywhere with her, </span><span style='color:green;font-weight:700;'>everywhere, </span>and it's super soft and cute.  <span style='color:red;font-weight:700;text-decoration:line-through;'>One of the ears </span><span style='color:green;font-weight:700;'>However, one ear </span>is <span style='color:red;font-weight:700;text-decoration:line-through;'>a bit </span><span style='color:green;font-weight:700;'>slightly </span>lower than the <span style='color:red;font-weight:700;text-decoration:line-through;'>other, and </span><span style='color:green;font-weight:700;'>other; </span>I don't think <span style='color:red;font-weight:700;text-decoration:line-through;'>that </span><span style='color:green;font-weight:700;'>this </span>was <span style='color:red;font-weight:700;text-decoration:line-through;'>designed to be asymmetrical. </span><span style='color:green;font-weight:700;'>intentional.  </span>It's <span style='color:green;font-weight:700;'>also </span>a bit <span style='color:red;font-weight:700;text-decoration:line-through;'>small </span><span style='color:green;font-weight:700;'>smaller than I expected </span>for <span style='color:red;font-weight:700;text-decoration:line-through;'>what I paid for it though. I think there might </span><span style='color:green;font-weight:700;'>the price.  There may </span>be <span style='color:red;font-weight:700;text-decoration:line-through;'>other </span><span style='color:green;font-weight:700;'>larger </span>options <span style='color:red;font-weight:700;text-decoration:line-through;'>that are bigger </span><span style='color:green;font-weight:700;'>available </span>for the same <span style='color:red;font-weight:700;text-decoration:line-through;'>price.  </span><span style='color:green;font-weight:700;'>cost.  </span>It arrived a day <span style='color:red;font-weight:700;text-decoration:line-through;'>earlier than expected, so I got </span><span style='color:green;font-weight:700;'>early, which allowed me </span>to <span style='color:red;font-weight:700;text-decoration:line-through;'>play with it myself before I gave it to my daughter.</span><span style='color:green;font-weight:700;'>enjoy</span>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "Mv7h0VFwDG-K",
        "outputId": "b1b4e096-4641-4f58-c604-21793d571700"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Review of Panda Plush Toy\n\nThis review assesses a recently purchased panda plush toy. While the toy's softness and appealing aesthetic initially proved successful in satisfying the intended recipient (the reviewer's daughter), several aspects warrant critical consideration.\n\nThe toy's diminutive size relative to its cost presents a significant drawback.  Although the plush is undeniably soft and cute, its small stature raises concerns regarding value for money.  A comparative market analysis might reveal comparable plush toys of larger dimensions at a similar price"
          },
          "metadata": {}
        }
      ]
    }
  ]
}